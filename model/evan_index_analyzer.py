import re
import os
import datetime
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

class EvanIndexAnalyzer:
    def __init__(self, results_path):
        self.results_path = results_path
        self.nph_values = []      # List of (id, value)
        self.non_nph_values = []  # List of (id, value)
        self.nph_data = []        # List of full data tuples (id, ant, cran, evan, pct)
        self.non_nph_data = []    # List of full data tuples (id, ant, cran, evan, pct)
        self.abnormal_cases = []  # List of (id, value)
        self.n_nph = 0
        self.n_non = 0
        self.load_data()

    def load_data(self):
        """å¾çµæœæ‘˜è¦æ–‡ä»¶åŠ è¼‰æ•¸æ“š"""
        if not os.path.exists(self.results_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°çµæœæ–‡ä»¶: {self.results_path}")

        with open(self.results_path, 'r') as f:
            content = f.read()

        # è§£ææ¸¬é‡çµæœè¡¨æ ¼
        # æ ¼å¼: | æ¡ˆä¾‹ ID | å‰è…³è·é›¢ (mm) | é¡±å…§å¯¬åº¦ (mm) | Evan Index | ç™¾åˆ†æ¯” | è™•ç†æ™‚é–“ |
        pattern = r'\| ([^\|]+) \| ([\d.]+) \| ([\d.]+) \| ([\d.]+) \| ([\d.]+)% \| [\d.]+s \|'
        matches = re.findall(pattern, content)

        for match in matches:
            case_id = match[0].strip()
            ant_dist = float(match[1])
            cran_width = float(match[2])
            evan_val = float(match[3])
            evan_pct = float(match[4])
            
            # éæ¿¾ç•°å¸¸å€¼ (Evan Index > 50%)
            if evan_pct > 50:
                self.abnormal_cases.append((case_id, evan_pct))
                continue
            
            data_tuple = (case_id, ant_dist, cran_width, evan_val, evan_pct)
            
            if 'âš ï¸ NPH' in case_id:
                clean_id = case_id.replace(' âš ï¸ NPH', '')
                self.nph_values.append((clean_id, evan_pct))
                self.nph_data.append((clean_id, ant_dist, cran_width, evan_val, evan_pct))
            else:
                self.non_nph_values.append((case_id, evan_pct))
                self.non_nph_data.append(data_tuple)

        self.n_nph = len(self.nph_values)
        self.n_non = len(self.non_nph_values)
        
        print(f"æ•¸æ“šåŠ è¼‰å®Œæˆ: NPH={self.n_nph}, é NPH={self.n_non}")

    def get_statistics(self, data_list):
        """ç²å–çµ±è¨ˆæ•¸æ“š"""
        values = [x[4] for x in data_list] if data_list else []
        ant_vals = [x[1] for x in data_list] if data_list else []
        cran_vals = [x[2] for x in data_list] if data_list else []
        
        count = len(values)
        if count == 0:
            return {
                'count': 0, 'min': 0, 'max': 0, 'avg': 0, 'median': 0,
                'min_ant': 0, 'max_ant': 0, 'avg_ant': 0,
                'min_cran': 0, 'max_cran': 0, 'avg_cran': 0
            }
            
        return {
            'count': count,
            'min': min(values),
            'max': max(values),
            'avg': sum(values)/count,
            'median': sorted(values)[count//2],
            'min_ant': min(ant_vals), 'max_ant': max(ant_vals), 'avg_ant': sum(ant_vals)/count,
            'min_cran': min(cran_vals), 'max_cran': max(cran_vals), 'avg_cran': sum(cran_vals)/count
        }

    def evaluate_threshold(self, threshold):
        """è©•ä¼°ç‰¹å®šé–¾å€¼çš„è¨ºæ–·æ•ˆèƒ½"""
        nph_vals = [x[1] for x in self.nph_values]
        non_nph_vals = [x[1] for x in self.non_nph_values]
        
        nph_above = sum(1 for v in nph_vals if v >= threshold)
        nph_below = self.n_nph - nph_above
        non_above = sum(1 for v in non_nph_vals if v >= threshold)
        non_below = self.n_non - non_above
        
        sens = nph_above / self.n_nph if self.n_nph else 0
        spec = non_below / self.n_non if self.n_non else 0
        ppv = nph_above / (nph_above + non_above) if (nph_above + non_above) > 0 else 0
        npv = non_below / (non_below + nph_below) if (non_below + nph_below) > 0 else 0
        acc = (nph_above + non_below) / (self.n_nph + self.n_non) if (self.n_nph + self.n_non) else 0
        
        return {
            'threshold': threshold,
            'sensitivity': sens,
            'specificity': spec,
            'ppv': ppv,
            'npv': npv,
            'accuracy': acc,
            'counts': {
                'tp': nph_above, 'fn': nph_below,
                'fp': non_above, 'tn': non_below
            }
        }

    def generate_report(self, output_path):
        """ç”Ÿæˆ Markdown å ±å‘Š"""
        nph_stats = self.get_statistics(self.nph_data)
        non_stats = self.get_statistics(self.non_nph_data)
        
        diff_idx = nph_stats['avg'] - non_stats['avg']
        diff_pct = (diff_idx / non_stats['avg']) * 100 if non_stats['avg'] else 0
        
        today = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        report = f"""# Evan Index æ°´è…¦ç—‡æŒ‡æ¨™è©•ä¼°åˆ†æå ±å‘Š

**åˆ†ææ—¥æœŸ**: {today}
**æ•¸æ“šä¾†æº**: 3D Evan Index æ‰¹æ¬¡è™•ç†çµæœ ({self.n_nph + self.n_non} å€‹æœ‰æ•ˆæ¡ˆä¾‹)

---

## åŸ·è¡Œæ‘˜è¦

æœ¬å ±å‘Šè©•ä¼°ã€ŒEvan Index (å‰è…³è·é›¢/é¡±å…§å¯¬åº¦æ¯”å€¼)ã€ä½œç‚ºæ°´è…¦ç—‡ (NPH) è¨ºæ–·æŒ‡æ¨™çš„å¯è¡Œæ€§ã€‚ç ”ç©¶çµæœé¡¯ç¤º,**æ­¤æŒ‡æ¨™å±•ç¾å„ªç•°çš„é‘‘åˆ¥èƒ½åŠ›**,NPH çµ„èˆ‡é NPH çµ„æœ‰ **{diff_pct:.1f}%** çš„å·®ç•°ã€‚

---

## æ•¸æ“šæ¦‚æ³

### æ¡ˆä¾‹åˆ†å¸ƒ
- **ç¸½æ¡ˆä¾‹æ•¸**: {self.n_nph + self.n_non} ä¾‹
- **æ°´è…¦ç—‡æ¡ˆä¾‹ (NPH)**: {self.n_nph} ä¾‹ ({self.n_nph/(self.n_nph+self.n_non)*100:.1f}%)
- **éæ°´è…¦ç—‡æ¡ˆä¾‹**: {self.n_non} ä¾‹ ({self.n_non/(self.n_nph+self.n_non)*100:.1f}%)

### é—œéµæŒ‡æ¨™çµ±è¨ˆ

#### æ°´è…¦ç—‡æ¡ˆä¾‹ (NPH, n={self.n_nph})

| æ¸¬é‡æŒ‡æ¨™ | æœ€å°å€¼ | æœ€å¤§å€¼ | å¹³å‡å€¼ | ä¸­ä½æ•¸ |
|---------|--------|--------|--------|--------|
| å‰è…³è·é›¢ (mm) | {nph_stats['min_ant']:.2f} | {nph_stats['max_ant']:.2f} | {nph_stats['avg_ant']:.2f} | - |
| é¡±å…§å¯¬åº¦ (mm) | {nph_stats['min_cran']:.2f} | {nph_stats['max_cran']:.2f} | {nph_stats['avg_cran']:.2f} | - |
| **Evan Index** | **{nph_stats['min']/100:.4f}** | **{nph_stats['max']/100:.4f}** | **{nph_stats['avg']/100:.4f}** | **{nph_stats['median']/100:.4f}** |
| **ç™¾åˆ†æ¯”** | **{nph_stats['min']:.2f}%** | **{nph_stats['max']:.2f}%** | **{nph_stats['avg']:.2f}%** | **{nph_stats['median']:.2f}%** |

#### éæ°´è…¦ç—‡æ¡ˆä¾‹ (é NPH, n={self.n_non})

| æ¸¬é‡æŒ‡æ¨™ | æœ€å°å€¼ | æœ€å¤§å€¼ | å¹³å‡å€¼ | ä¸­ä½æ•¸ |
|---------|--------|--------|--------|--------|
| å‰è…³è·é›¢ (mm) | {non_stats['min_ant']:.2f} | {non_stats['max_ant']:.2f} | {non_stats['avg_ant']:.2f} | - |
| é¡±å…§å¯¬åº¦ (mm) | {non_stats['min_cran']:.2f} | {non_stats['max_cran']:.2f} | {non_stats['avg_cran']:.2f} | - |
| **Evan Index** | **{non_stats['min']/100:.4f}** | **{non_stats['max']/100:.4f}** | **{non_stats['avg']/100:.4f}** | **{non_stats['median']/100:.4f}** |
| **ç™¾åˆ†æ¯”** | **{non_stats['min']:.2f}%** | **{non_stats['max']:.2f}%** | **{non_stats['avg']:.2f}%** | **{non_stats['median']:.2f}%** |

#### çµ„é–“å·®ç•°

| æŒ‡æ¨™ | NPH å¹³å‡å€¼ | é NPH å¹³å‡å€¼ | å·®ç•° | å·®ç•°ç™¾åˆ†æ¯” |
|-----|-----------|-------------|------|-----------| 
| å‰è…³è·é›¢ | {nph_stats['avg_ant']:.2f} mm | {non_stats['avg_ant']:.2f} mm | {nph_stats['avg_ant'] - non_stats['avg_ant']:+.2f} mm | {(nph_stats['avg_ant'] - non_stats['avg_ant'])/non_stats['avg_ant']*100:+.1f}% |
| é¡±å…§å¯¬åº¦ | {nph_stats['avg_cran']:.2f} mm | {non_stats['avg_cran']:.2f} mm | {nph_stats['avg_cran'] - non_stats['avg_cran']:+.2f} mm | {(nph_stats['avg_cran'] - non_stats['avg_cran'])/non_stats['avg_cran']*100:+.1f}% |
| **Evan Index** | **{nph_stats['avg']/100:.4f}** | **{non_stats['avg']/100:.4f}** | **{diff_idx/100:+.4f}** | **{diff_pct:+.1f}%** |

---

## ä¸»è¦ç™¼ç¾

### âœ… å„ªå‹¢

1. **çµ„é–“å·®ç•°é¡¯è‘—**: é” {diff_pct:.1f}%ï¼Œé è¶…è‡¨åºŠå¯ç”¨æ¨™æº–
2. **NPH çµ„å¹³å‡å€¼**: {nph_stats['avg']:.2f}%
3. **é NPH çµ„å¹³å‡å€¼**: {non_stats['avg']:.2f}%

### 2. é–¾å€¼æ•ˆèƒ½è©•ä¼°

ä¸‹è¡¨å±•ç¤ºä¸åŒé–¾å€¼ä¸‹çš„è¨ºæ–·æ•ˆèƒ½ï¼š

| é–¾å€¼ | éˆæ•åº¦ | ç‰¹ç•°æ€§ | PPV | NPV | æº–ç¢ºåº¦ |
|------|--------|--------|-----|-----|--------|
"""
        for t in [28, 30, 32, 33, 35]:
            m = self.evaluate_threshold(t)
            report += f"| **{t}%** | {m['sensitivity']*100:.1f}% | {m['specificity']*100:.1f}% | {m['ppv']*100:.1f}% | {m['npv']*100:.1f}% | {m['accuracy']*100:.1f}% |\n"

        report += f"""
---

## è‡¨åºŠæ‡‰ç”¨å»ºè­°

### ğŸ“Š å»ºè­°ä½¿ç”¨ç­–ç•¥

```
Evan Index < 28%  â†’ NPH å¯èƒ½æ€§ä½
Evan Index 28-33% â†’ ç°è‰²åœ°å¸¶ (éœ€è¬¹æ…è©•ä¼°)
Evan Index > 33%  â†’ é«˜åº¦æ‡·ç–‘ NPH (PPV > 90%)
```

---

## çµè«–

**Evan Index åœ¨æœ¬æ•¸æ“šé›†ä¸­å±•ç¾å„ªç•°çš„ NPH è¨ºæ–·æ•ˆèƒ½**:

1. âœ… **çµ„é–“å·®ç•°é¡¯è‘—**: {diff_pct:.1f}%
2. âœ… **æ¨£æœ¬æ•¸**: {self.n_nph + self.n_non} ä¾‹ (NPH: {self.n_nph}, é NPH: {self.n_non})

---

## é™„éŒ„: NPH æ¡ˆä¾‹åˆ†å¸ƒ (Top 20)

| æ’åº | æ¡ˆä¾‹ ID | å‰è…³è·é›¢ (mm) | é¡±å…§å¯¬åº¦ (mm) | Evan Index | ç™¾åˆ†æ¯” |
|-----|---------|---------------|---------------|-----------|--------|
"""
        sorted_nph = sorted(self.nph_data, key=lambda x: x[4], reverse=True)
        for i, item in enumerate(sorted_nph[:20]):
            report += f"| {i+1} | {item[0]} | {item[1]:.2f} | {item[2]:.2f} | {item[3]:.4f} | {item[4]:.2f}% |\n"

        report += """
---

## é™„éŒ„: é NPH é«˜å€¼æ¡ˆä¾‹ (Top 10, > 30%)

| æ’åº | æ¡ˆä¾‹ ID | å‰è…³è·é›¢ (mm) | é¡±å…§å¯¬åº¦ (mm) | Evan Index | ç™¾åˆ†æ¯” |
|-----|---------|---------------|---------------|-----------|--------|
"""
        sorted_non_nph = sorted(self.non_nph_data, key=lambda x: x[4], reverse=True)
        count = 0
        for i, item in enumerate(sorted_non_nph):
            if item[4] < 30 and count >= 10: break
            if item[4] >= 30 or count < 10:
                report += f"| {i+1} | {item[0]} | {item[1]:.2f} | {item[2]:.2f} | {item[3]:.4f} | {item[4]:.2f}% |\n"
                count += 1

        report += f"\n**å ±å‘Šç”¢ç”Ÿ**: 3D NPH Indicators ç³»çµ±\n**æœ€å¾Œæ›´æ–°**: {today}\n"

        with open(output_path, 'w') as f:
            f.write(report)
    def generate_roc_curve(self, output_path):
        """ç”Ÿæˆ ROC æ›²ç·š"""
        # æº–å‚™æ•¸æ“š: NPH=1, Non-NPH=0
        y_true = [1] * len(self.nph_values) + [0] * len(self.non_nph_values)
        # æå– Evan Index å€¼ (ç™¾åˆ†æ¯”)
        y_scores = [x[1] for x in self.nph_values] + [x[1] for x in self.non_nph_values]
        
        # è¨ˆç®— ROC æ›²ç·š
        fpr, tpr, thresholds = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        # ç¹ªè£½
        plt.figure(figsize=(10, 8))
        plt.plot(fpr, tpr, color='#2563eb', lw=3, label=f'ROC curve (AUC = {roc_auc:.3f})')
        plt.plot([0, 1], [0, 1], color='#94a3b8', lw=2, linestyle='--', label='Random classifier')
        
        # æ¨™è¨˜é—œéµé–¾å€¼é» (28, 30, 32, 33, 35)
        key_thresholds = [28, 30, 32, 33, 35]
        for thresh in key_thresholds:
            # æ‰¾åˆ°æœ€æ¥è¿‘ threshold çš„é»
            # thresholds æ˜¯å¾å¤§åˆ°å°æ’åˆ—çš„
            idx = (np.abs(thresholds - thresh)).argmin()
            
            plt.scatter(fpr[idx], tpr[idx], s=150, zorder=5, edgecolors='white', linewidth=2)
            plt.annotate(f'{thresh}%\n(Sens:{tpr[idx]:.0%}, Spec:{1-fpr[idx]:.0%})', 
                         xy=(fpr[idx], tpr[idx]), 
                         xytext=(fpr[idx]+0.05, tpr[idx]-0.1),
                         fontsize=10, fontweight='bold',
                         arrowprops=dict(arrowstyle='->', color='#64748b'))

        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=14)
        plt.ylabel('True Positive Rate (Sensitivity)', fontsize=14)
        plt.title(f'ROC Curve for Evan Index NPH Classification\n(n={self.n_nph + self.n_non}, NPH={self.n_nph}, Non-NPH={self.n_non})', fontsize=16, fontweight='bold')
        plt.legend(loc="lower right", fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ  AUC æ–‡å­—
        plt.text(0.6, 0.2, f'AUC = {roc_auc:.3f}', fontsize=20, fontweight='bold', 
                 bbox=dict(boxstyle='round', facecolor='#dbeafe', edgecolor='#2563eb', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ROC æ›²ç·šå·²ç”Ÿæˆ: {output_path}")

if __name__ == "__main__":
    import datetime
    import os
    import numpy as np # Need numpy for argmin
    analyzer = EvanIndexAnalyzer('/Users/lujingyuan/Project/3d-nph-indicators/result/evan_index/results_summary.md')
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    
    # Generate Report
    output_filename = f'result/evan_index/evan_index_analysis_{timestamp}.md'
    analyzer.generate_report(os.path.join(os.getcwd(), output_filename))
    
    # Generate ROC Curve
    roc_filename = f'result/evan_index/roc_curve_{timestamp}.png'
    analyzer.generate_roc_curve(os.path.join(os.getcwd(), roc_filename))

