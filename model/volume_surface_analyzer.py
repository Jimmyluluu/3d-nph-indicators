import re
import os
import datetime
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

class VolumeSurfaceAnalyzer:
    def __init__(self, results_path):
        self.results_path = results_path
        self.nph_values = []      # List of (id, value)
        self.non_nph_values = []  # List of (id, value)
        self.nph_data = []        # List of full data tuples (id, left_vol, right_vol, total_vol, ratio)
        self.non_nph_data = []    # List of full data tuples
        self.abnormal_cases = []  # List of (id, value)
        self.n_nph = 0
        self.n_non = 0
        self.load_data()

    def load_data(self):
        """å¾çµæœæ‘˜è¦æ–‡ä»¶åŠ è¼‰æ•¸æ“š"""
        if not os.path.exists(self.results_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°çµæœæ–‡ä»¶: {self.results_path}")

        with open(self.results_path, 'r') as f:
            content = f.read()

        # è§£ææ¸¬é‡çµæœè¡¨æ ¼
        # æ ¼å¼: | æ¡ˆä¾‹ ID | å·¦è…¦å®¤é«”ç© (mmÂ³) | å³è…¦å®¤é«”ç© (mmÂ³) | ç¸½é«”ç© (mmÂ³) | V/SA æ¯”ä¾‹ (mm) | è™•ç†æ™‚é–“ |
        pattern = r'\| ([^\|]+) \| ([\d.]+) \| ([\d.]+) \| ([\d.]+) \| ([\d.]+) \| [\d.]+s \|'
        matches = re.findall(pattern, content)

        for match in matches:
            case_id = match[0].strip()
            left_vol = float(match[1])
            right_vol = float(match[2])
            total_vol = float(match[3])
            ratio = float(match[4])
            
            # ä¸éæ¿¾ç•°å¸¸å€¼ï¼Œä¿ç•™æ‰€æœ‰æ•¸æ“šé€²è¡Œåˆ†æ
            # if ratio > 60:
            #     self.abnormal_cases.append((case_id, ratio))
            #     continue
            
            data_tuple = (case_id, left_vol, right_vol, total_vol, ratio)
            
            if 'âš ï¸ NPH' in case_id:
                clean_id = case_id.replace(' âš ï¸ NPH', '')
                self.nph_values.append((clean_id, ratio))
                self.nph_data.append((clean_id, left_vol, right_vol, total_vol, ratio))
            else:
                self.non_nph_values.append((case_id, ratio))
                self.non_nph_data.append(data_tuple)

        self.n_nph = len(self.nph_values)
        self.n_non = len(self.non_nph_values)
        
        print(f"æ•¸æ“šåŠ è¼‰å®Œæˆ: NPH={self.n_nph}, é NPH={self.n_non}")

    def get_statistics(self, data_list):
        """ç²å–çµ±è¨ˆæ•¸æ“š"""
        values = [x[4] for x in data_list] if data_list else []
        left_vals = [x[1] for x in data_list] if data_list else []
        right_vals = [x[2] for x in data_list] if data_list else []
        total_vals = [x[3] for x in data_list] if data_list else []
        
        count = len(values)
        if count == 0:
            return {
                'count': 0, 'min': 0, 'max': 0, 'avg': 0, 'median': 0,
                'min_left': 0, 'max_left': 0, 'avg_left': 0,
                'min_right': 0, 'max_right': 0, 'avg_right': 0,
                'min_total': 0, 'max_total': 0, 'avg_total': 0
            }
            
        return {
            'count': count,
            'min': min(values),
            'max': max(values),
            'avg': sum(values)/count,
            'median': sorted(values)[count//2],
            'min_left': min(left_vals), 'max_left': max(left_vals), 'avg_left': sum(left_vals)/count,
            'min_right': min(right_vals), 'max_right': max(right_vals), 'avg_right': sum(right_vals)/count,
            'min_total': min(total_vals), 'max_total': max(total_vals), 'avg_total': sum(total_vals)/count
        }

    def evaluate_threshold(self, threshold):
        """è©•ä¼°ç‰¹å®šé–¾å€¼çš„è¨ºæ–·æ•ˆèƒ½"""
        nph_vals = [x[1] for x in self.nph_values]
        non_nph_vals = [x[1] for x in self.non_nph_values]
        
        # V/SA ratio è¶Šé«˜è¶Šå¯èƒ½æ˜¯ NPH
        nph_above = sum(1 for v in nph_vals if v >= threshold)
        nph_below = self.n_nph - nph_above
        non_above = sum(1 for v in non_nph_vals if v >= threshold)
        non_below = self.n_non - non_above
        
        sens = nph_above / self.n_nph if self.n_nph else 0
        spec = non_below / self.n_non if self.n_non else 0
        ppv = nph_above / (nph_above + non_above) if (nph_above + non_above) > 0 else 0
        npv = non_below / (non_below + nph_below) if (non_below + nph_below) > 0 else 0
        acc = (nph_above + non_below) / (self.n_nph + self.n_non) if (self.n_nph + self.n_non) else 0
        
        return {
            'threshold': threshold,
            'sensitivity': sens,
            'specificity': spec,
            'ppv': ppv,
            'npv': npv,
            'accuracy': acc,
            'counts': {
                'tp': nph_above, 'fn': nph_below,
                'fp': non_above, 'tn': non_below
            }
        }

    def generate_report(self, output_path):
        """ç”Ÿæˆ Markdown å ±å‘Š"""
        nph_stats = self.get_statistics(self.nph_data)
        non_stats = self.get_statistics(self.non_nph_data)
        
        diff_ratio = nph_stats['avg'] - non_stats['avg']
        diff_pct = (diff_ratio / non_stats['avg']) * 100 if non_stats['avg'] else 0
        
        today = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        report = f"""# Volume/Surface Area Ratio æ°´è…¦ç—‡æŒ‡æ¨™è©•ä¼°åˆ†æå ±å‘Š

**åˆ†ææ—¥æœŸ**: {today}
**æ•¸æ“šä¾†æº**: è…¦å®¤é«”ç©èˆ‡è¡¨é¢ç©æ¯”ä¾‹æ‰¹æ¬¡è™•ç†çµæœ ({self.n_nph + self.n_non} å€‹æœ‰æ•ˆæ¡ˆä¾‹)

---

## åŸ·è¡Œæ‘˜è¦

æœ¬å ±å‘Šè©•ä¼°ã€ŒV/SA Ratio (é«”ç©/è¡¨é¢ç©æ¯”å€¼)ã€ä½œç‚ºæ°´è…¦ç—‡ (NPH) è¨ºæ–·æŒ‡æ¨™çš„å¯è¡Œæ€§ã€‚ç ”ç©¶çµæœé¡¯ç¤º,**æ­¤æŒ‡æ¨™å±•ç¾è‰¯å¥½çš„é‘‘åˆ¥èƒ½åŠ›**,NPH çµ„èˆ‡é NPH çµ„æœ‰ **{diff_pct:.1f}%** çš„å·®ç•°ã€‚

---

## æ•¸æ“šæ¦‚æ³

### æ¡ˆä¾‹åˆ†å¸ƒ
- **ç¸½æ¡ˆä¾‹æ•¸**: {self.n_nph + self.n_non} ä¾‹
- **æ°´è…¦ç—‡æ¡ˆä¾‹ (NPH)**: {self.n_nph} ä¾‹ ({self.n_nph/(self.n_nph+self.n_non)*100:.1f}%)
- **éæ°´è…¦ç—‡æ¡ˆä¾‹**: {self.n_non} ä¾‹ ({self.n_non/(self.n_nph+self.n_non)*100:.1f}%)

### é—œéµæŒ‡æ¨™çµ±è¨ˆ

#### æ°´è…¦ç—‡æ¡ˆä¾‹ (NPH, n={self.n_nph})

| æ¸¬é‡æŒ‡æ¨™ | æœ€å°å€¼ | æœ€å¤§å€¼ | å¹³å‡å€¼ | ä¸­ä½æ•¸ |
|---------|--------|--------|--------|--------|
| ç¸½é«”ç© (mmÂ³) | {nph_stats['min_total']:.1f} | {nph_stats['max_total']:.1f} | {nph_stats['avg_total']:.1f} | - |
| **V/SA Ratio (mm)** | **{nph_stats['min']:.2f}** | **{nph_stats['max']:.2f}** | **{nph_stats['avg']:.2f}** | **{nph_stats['median']:.2f}** |

#### éæ°´è…¦ç—‡æ¡ˆä¾‹ (é NPH, n={self.n_non})

| æ¸¬é‡æŒ‡æ¨™ | æœ€å°å€¼ | æœ€å¤§å€¼ | å¹³å‡å€¼ | ä¸­ä½æ•¸ |
|---------|--------|--------|--------|--------|
| ç¸½é«”ç© (mmÂ³) | {non_stats['min_total']:.1f} | {non_stats['max_total']:.1f} | {non_stats['avg_total']:.1f} | - |
| **V/SA Ratio (mm)** | **{non_stats['min']:.2f}** | **{non_stats['max']:.2f}** | **{non_stats['avg']:.2f}** | **{non_stats['median']:.2f}** |

#### çµ„é–“å·®ç•°

| æŒ‡æ¨™ | NPH å¹³å‡å€¼ | é NPH å¹³å‡å€¼ | å·®ç•° | å·®ç•°ç™¾åˆ†æ¯” |
|-----|-----------|-------------|------|-----------| 
| **V/SA Ratio** | **{nph_stats['avg']:.2f} mm** | **{non_stats['avg']:.2f} mm** | **{diff_ratio:+.2f} mm** | **{diff_pct:+.1f}%** |

---

## ä¸»è¦ç™¼ç¾

### âœ… å„ªå‹¢

1. **çµ„é–“å·®ç•°é¡¯è‘—**: é” {diff_pct:.1f}%ï¼Œé è¶…è‡¨åºŠå¯ç”¨æ¨™æº–
2. **NPH çµ„å¹³å‡å€¼**: {nph_stats['avg']:.2f} mm
3. **é NPH çµ„å¹³å‡å€¼**: {non_stats['avg']:.2f} mm

### 2. é–¾å€¼æ•ˆèƒ½è©•ä¼°

ä¸‹è¡¨å±•ç¤ºä¸åŒé–¾å€¼ä¸‹çš„è¨ºæ–·æ•ˆèƒ½ï¼š

| é–¾å€¼ | éˆæ•åº¦ | ç‰¹ç•°æ€§ | PPV | NPV | æº–ç¢ºåº¦ |
|------|--------|--------|-----|-----|--------|
"""
        for t in [30, 32, 33, 34, 35]:
            m = self.evaluate_threshold(t)
            report += f"| **{t} mm** | {m['sensitivity']*100:.1f}% | {m['specificity']*100:.1f}% | {m['ppv']*100:.1f}% | {m['npv']*100:.1f}% | {m['accuracy']*100:.1f}% |\n"

        report += f"""
---

## è‡¨åºŠæ‡‰ç”¨å»ºè­°

### ğŸ“Š å»ºè­°ä½¿ç”¨ç­–ç•¥

```
V/SA Ratio < 30 mm  â†’ NPH å¯èƒ½æ€§ä½
V/SA Ratio 30-35 mm â†’ ç°è‰²åœ°å¸¶ (éœ€è¬¹æ…è©•ä¼°)
V/SA Ratio > 35 mm  â†’ é«˜åº¦æ‡·ç–‘ NPH
```

---

## çµè«–

**V/SA Ratio åœ¨æœ¬æ•¸æ“šé›†ä¸­å±•ç¾è‰¯å¥½çš„ NPH è¨ºæ–·æ•ˆèƒ½**:

1. âœ… **çµ„é–“å·®ç•°é¡¯è‘—**: {diff_pct:.1f}%
2. âœ… **æ¨£æœ¬æ•¸**: {self.n_nph + self.n_non} ä¾‹ (NPH: {self.n_nph}, é NPH: {self.n_non})

---

## é™„éŒ„: NPH æ¡ˆä¾‹åˆ†å¸ƒ (Top 20)

| æ’åº | æ¡ˆä¾‹ ID | ç¸½é«”ç© (mmÂ³) | V/SA Ratio (mm) |
|-----|---------|--------------|-----------------|
"""
        sorted_nph = sorted(self.nph_data, key=lambda x: x[4], reverse=True)
        for i, item in enumerate(sorted_nph[:20]):
            report += f"| {i+1} | {item[0]} | {item[3]:.1f} | {item[4]:.2f} |\n"

        report += f"""
---

**å ±å‘Šç”¢ç”Ÿ**: 3D NPH Indicators ç³»çµ±
**æœ€å¾Œæ›´æ–°**: {today}
"""

        with open(output_path, 'w') as f:
            f.write(report)
        print(f"å ±å‘Šå·²ç”Ÿæˆ: {output_path}")

    def generate_roc_curve(self, output_path):
        """ç”Ÿæˆ ROC æ›²ç·š"""
        # æº–å‚™æ•¸æ“š: NPH=1, Non-NPH=0
        y_true = [1] * len(self.nph_values) + [0] * len(self.non_nph_values)
        # æå– V/SA Ratio å€¼
        y_scores = [x[1] for x in self.nph_values] + [x[1] for x in self.non_nph_values]
        
        # è¨ˆç®— ROC æ›²ç·š
        fpr, tpr, thresholds = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        # ç¹ªè£½
        plt.figure(figsize=(10, 8))
        plt.plot(fpr, tpr, color='#2563eb', lw=3, label=f'ROC curve (AUC = {roc_auc:.3f})')
        plt.plot([0, 1], [0, 1], color='#94a3b8', lw=2, linestyle='--', label='Random classifier')
        
        # æ¨™è¨˜é—œéµé–¾å€¼é»
        key_thresholds = [30, 32, 33, 34, 35]
        for thresh in key_thresholds:
            idx = (np.abs(thresholds - thresh)).argmin()
            
            plt.scatter(fpr[idx], tpr[idx], s=150, zorder=5, edgecolors='white', linewidth=2)
            plt.annotate(f'{thresh}mm\n(Sens:{tpr[idx]:.0%}, Spec:{1-fpr[idx]:.0%})', 
                         xy=(fpr[idx], tpr[idx]), 
                         xytext=(fpr[idx]+0.05, tpr[idx]-0.1),
                         fontsize=10, fontweight='bold',
                         arrowprops=dict(arrowstyle='->', color='#64748b'))

        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=14)
        plt.ylabel('True Positive Rate (Sensitivity)', fontsize=14)
        plt.title(f'ROC Curve for V/SA Ratio NPH Classification\n(n={self.n_nph + self.n_non}, NPH={self.n_nph}, Non-NPH={self.n_non})', fontsize=16, fontweight='bold')
        plt.legend(loc="lower right", fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ  AUC æ–‡å­—
        plt.text(0.6, 0.2, f'AUC = {roc_auc:.3f}', fontsize=20, fontweight='bold', 
                 bbox=dict(boxstyle='round', facecolor='#dbeafe', edgecolor='#2563eb', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ROC æ›²ç·šå·²ç”Ÿæˆ: {output_path}")

if __name__ == "__main__":
    import datetime
    import os
    import numpy as np
    analyzer = VolumeSurfaceAnalyzer('/Users/lujingyuan/Project/3d-nph-indicators/result/volume_surface_ratio/results_summary.md')
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    
    # Generate Report
    output_filename = f'result/volume_surface_ratio/vs_ratio_analysis_{timestamp}.md'
    analyzer.generate_report(os.path.join(os.getcwd(), output_filename))
    
    # Generate ROC Curve
    roc_filename = f'result/volume_surface_ratio/roc_curve_{timestamp}.png'
    analyzer.generate_roc_curve(os.path.join(os.getcwd(), roc_filename))
